import streamlit as st
import os, sys, json, tempfile, uuid

# --- 1. ç¯å¢ƒè¡¥ä¸ ---
venv_pkg = os.path.join(os.getcwd(), "venv", "Lib", "site-packages")
if venv_pkg not in sys.path: sys.path.insert(0, venv_pkg)

try:
    from langchain_openai import ChatOpenAI
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_core.output_parsers import StrOutputParser
    from langchain_core.runnables import RunnablePassthrough
    from langchain_community.document_loaders import PyPDFLoader, TextLoader, Docx2txtLoader
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langchain_community.embeddings import HuggingFaceEmbeddings
    from langchain_community.vectorstores import Chroma
except Exception as e:
    st.error(f"ç»„ä»¶ç¼ºå¤±ï¼š{e}"); st.stop()

# --- 2. åŸºç¡€é…ç½®ä¸ Secrets åŠ è½½ ---
DB_PREFIX = "db_"
HISTORY_FILE = "all_chats_v3.json"
# ä» Streamlit äº‘ç«¯åå°è¯»å– Key
secret_key = st.secrets.get("DEEPSEEK_API_KEY", "")

@st.cache_resource
def get_embedding_model():
    return HuggingFaceEmbeddings(model_name="BAAI/bge-small-zh-v1.5")

def load_all_chats():
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, "r", encoding="utf-8") as f: return json.load(f)
    return {}

def save_all_chats(chats):
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(chats, f, ensure_ascii=False, indent=2)

# --- 3. é¡µé¢è®¾ç½® ---
st.set_page_config(page_title="DeepSeek é›†å›¢å…¨èƒ½æ™ºåº“", layout="wide")

# --- 4. æƒé™æ ¡éªŒåŠŸèƒ½ (å¼ºåˆ¶æ‰‹åŠ¨è¾“å…¥ 6688ï¼Œç¡®ä¿é“¾æ¥å®‰å…¨) ---
def check_password():
    def password_entered():
        # è¿™é‡Œæ˜¯ä½ çš„è®¿é—®å¯†ç ï¼Œä½ å¯ä»¥éšæ—¶ä¿®æ”¹è¿™ä¸ªå­—ç¬¦ä¸²
        if st.session_state["password"] == "6688": 
            st.session_state["password_correct"] = True
            del st.session_state["password"] 
        else:
            st.session_state["password_correct"] = False

    if "password_correct" not in st.session_state:
        st.title("ğŸ” ç§æœ‰æ™ºåº“è®¿é—®æˆæƒ")
        st.text_input("è¯·è¾“å…¥è®¿é—®æˆæƒç ", type="password", on_change=password_entered, key="password")
        st.info("æç¤ºï¼šæ­¤ä¸ºä¸ªäººç§æœ‰åŠå…¬æ™ºåº“ï¼Œä»…é™æˆæƒä½¿ç”¨ã€‚")
        return False
    elif not st.session_state["password_correct"]:
        st.title("ğŸ” ç§æœ‰æ™ºåº“è®¿é—®æˆæƒ")
        st.text_input("æˆæƒç é”™è¯¯ï¼Œè¯·é‡æ–°è¾“å…¥", type="password", on_change=password_entered, key="password")
        st.error("âŒ æˆæƒå¤±è´¥")
        return False
    else:
        return True

# æ‰§è¡Œå¯†ç æ ¡éªŒ
if not check_password():
    st.stop() 

# ç™»å½•æˆåŠŸåçš„åˆå§‹åŒ–
if "all_chats" not in st.session_state: st.session_state.all_chats = load_all_chats()
if "current_chat_id" not in st.session_state: st.session_state.current_chat_id = None

# --- 5. ä¾§è¾¹æ  ---
with st.sidebar:
    st.title("ğŸ“‚ æ™ºåº“ç®¡ç†ä¸­å¿ƒ")
    
    # ğŸ”‘ æ¥å£é…ç½®ï¼šä¼˜å…ˆä½¿ç”¨ Secrets
    st.subheader("ğŸ”‘ æ¥å£é…ç½®")
    if secret_key:
        api_key = secret_key
        st.success("âœ… DeepSeek Key å·²è‡ªåŠ¨ä» Secrets åŠ è½½")
    else:
        api_key = st.text_input("DeepSeek API Key", type="password")

    st.divider()
    
    # A. è·¨åº“æ£€ç´¢å¼€å…³
    st.subheader("ğŸ› ï¸ æ£€ç´¢æ¨¡å¼")
    multi_db_mode = st.toggle("ğŸŒ å¼€å¯å…¨åº“è”åˆæ£€ç´¢", value=False)
    
    # B. çŸ¥è¯†åº“ç»´æŠ¤
    with st.expander("âœ¨ çŸ¥è¯†åº“ç»´æŠ¤ (ä¸Šä¼ /æ–°å»º)"):
        existing_dirs = [d.replace(DB_PREFIX, "") for d in os.listdir(".") if os.path.isdir(d) and d.startswith(DB_PREFIX)]
        op_mode = st.radio("æ¨¡å¼", ["ç°æœ‰åˆ†ç±»", "æ–°åˆ†ç±»"], horizontal=True)
        target_cat = st.selectbox("é€‰æ‹©åˆ†ç±»", existing_dirs) if op_mode == "ç°æœ‰åˆ†ç±»" else st.text_input("æ–°åˆ†ç±»åç§°")
        uploaded_files = st.file_uploader("ä¸Šä¼ æ–‡ä»¶", accept_multiple_files=True)
        
        if st.button("ğŸš€ è¿è¡Œæ„å»º"):
            if not target_cat or not uploaded_files: st.warning("è¯·å®Œå–„ä¿¡æ¯")
            else:
                with st.spinner("å¤„ç†ä¸­..."):
                    all_docs = []
                    for f in uploaded_files:
                        ext = os.path.splitext(f.name)[-1].lower()
                        with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as tmp:
                            tmp.write(f.getvalue()); tmp_path = tmp.name
                        try:
                            if ext == ".pdf": loader = PyPDFLoader(tmp_path)
                            elif ext == ".docx": loader = Docx2txtLoader(tmp_path)
                            else: loader = TextLoader(tmp_path, encoding="utf-8")
                            all_docs.extend([d for d in loader.load() if d.page_content.strip()])
                        finally: os.unlink(tmp_path)
                    
                    if all_docs:
                        splits = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=100).split_documents(all_docs)
                        Chroma.from_documents(documents=splits, embedding=get_embedding_model(), persist_directory=f"./{DB_PREFIX}{target_cat}")
                        st.success("æ„å»ºæˆåŠŸï¼"); st.rerun()

    st.divider()
    
    # C. æ£€ç´¢èŒƒå›´
    st.subheader("ğŸ” é—®ç­”æ£€ç´¢èŒƒå›´")
    all_cats = [d.replace(DB_PREFIX, "") for d in os.listdir(".") if os.path.isdir(d) and d.startswith(DB_PREFIX)]
    selected_cat = st.selectbox("å½“å‰æé—®åŸºäºï¼š", all_cats if all_cats else ["é»˜è®¤"], disabled=multi_db_mode)

    st.divider()
    
    # D. å†å²è¯é¢˜
    st.subheader("ğŸ•™ å†å²è¯é¢˜")
    if st.button("â• å¼€å¯æ–°å¯¹è¯"): st.session_state.current_chat_id = None; st.rerun()
    for cid, cdata in reversed(list(st.session_state.all_chats.items())):
        if st.button(f"ğŸ’¬ {cdata['title']}", key=cid, use_container_width=True):
            st.session_state.current_chat_id = cid; st.rerun()

# --- 6. ä¸»ç•Œé¢ä¸é—®ç­”é€»è¾‘ ---
st.markdown(f"### ğŸ¯ æ¨¡å¼ï¼š{'å…¨åº“è”åˆæ£€ç´¢' if multi_db_mode else f'å•åº“æ£€ç´¢({selected_cat})'}")

if st.session_state.current_chat_id:
    for m in st.session_state.all_chats[st.session_state.current_chat_id]["messages"]:
        with st.chat_message(m["role"]): st.markdown(m["content"])
else:
    st.info("è¯·åœ¨ä¸‹æ–¹è¾“å…¥é—®é¢˜ã€‚é€šè¿‡ä¾§è¾¹æ ç®¡ç†åˆ†ç±»åº“ï¼Œè¾“å…¥ 6688 æˆæƒç å³å¯è®¿é—®ã€‚")

if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    if not api_key: 
        st.error("âŒ æœªæ£€æµ‹åˆ° API Keyï¼Œè¯·åœ¨ä¾§è¾¹æ é…ç½®æˆ–æ£€æŸ¥ Secretsã€‚")
        st.stop()
        
    with st.chat_message("user"): st.markdown(prompt)
    if not st.session_state.current_chat_id:
        cid = str(uuid.uuid4()); st.session_state.current_chat_id = cid
        st.session_state.all_chats[cid] = {"title": prompt[:12], "messages": []}

    with st.chat_message("assistant"):
        with st.spinner("æ­£åœ¨è·¨åº“æ£€ç´¢èµ„æ–™..."):
            try:
                combined_context = ""
                search_list = all_cats if multi_db_mode else [selected_cat]
                
                for cat in search_list:
                    db_p = f"./{DB_PREFIX}{cat}"
                    if os.path.exists(db_p):
                        vdb = Chroma(persist_directory=db_p, embedding_function=get_embedding_model())
                        docs = vdb.as_retriever(search_kwargs={"k": 3}).get_relevant_documents(prompt)
                        combined_context += f"\n\n--- æ¥è‡ªã€{cat}ã€‘çš„å‚è€ƒèµ„æ–™ ---\n"
                        combined_context += "\n".join([d.page_content for d in docs])
                
                if not combined_context.strip():
                    response = "æœªèƒ½åœ¨ä»»ä½•çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ç›¸å…³èµ„æ–™ã€‚"
                else:
                    llm = ChatOpenAI(model='deepseek-chat', openai_api_key=api_key, openai_api_base="https://api.deepseek.com", temperature=0.1)
                    prompt_tmpl = ChatPromptTemplate.from_template("ä½ æ˜¯ä¸€ä¸ªä¼ä¸šåŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹èµ„æ–™å›ç­”ã€‚å¦‚æœèµ„æ–™æ¥è‡ªä¸åŒåº“ï¼Œè¯·å¯¹æ¯”åˆ†æã€‚\nèµ„æ–™ï¼š{context}\né—®é¢˜ï¼š{question}")
                    chain = ({"context": lambda x: combined_context, "question": RunnablePassthrough()} | prompt_tmpl | llm | StrOutputParser())
                    response = chain.invoke(prompt)
                
                st.markdown(response)
                st.session_state.all_chats[st.session_state.current_chat_id]["messages"].append({"role": "user", "content": prompt})
                st.session_state.all_chats[st.session_state.current_chat_id]["messages"].append({"role": "assistant", "content": response})
                save_all_chats(st.session_state.all_chats)
            except Exception as e: st.error(f"å‡ºé”™ï¼š{e}")
